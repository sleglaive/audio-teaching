{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#F5F5F5; border-color:#C8C8C8\">\n",
    "<strong>Acknowledgment:</strong> This file is adapted from a notebook created by <a href=\"https://www.audiolabs-erlangen.de/fau/professor/mueller\">Meinard MÃ¼ller</a> (available <a href=\"https://www.audiolabs-erlangen.de/resources/MIR/FMP/C8/C8S3_NMFbasic.html\">here</a>) that was published along with the book  <a href=\"https://www.audiolabs-erlangen.de/fau/professor/mueller/bookFMP\"> Fundamentals of Music Processing</a>.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity #1 - NMF on a toy example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  IS-NMF multiplicative update rules\n",
    "\n",
    "In the following code cell, you have to complete a function that implements the multiplicative update rules for NMF with the Itakura-Saito divergence, as studied in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IS_div(V, V_hat):\n",
    "    \"\"\"\n",
    "    Returns the IS divergence between V and V_hat.\n",
    "    \"\"\"\n",
    "    F, N = V.shape\n",
    "    return np.sum( V/(V_hat) - np.log(V/V_hat) - np.ones((F,N)) )/(F*N)\n",
    "\n",
    "def IS_NMF(V, K, niter=1000, W=None, H=None, verbose=False):\n",
    "    \"\"\"NMF algorithm with Itakura-Saito divergence\n",
    "    \n",
    "    Args: \n",
    "        V: Nonnegative matrix of size F x N\n",
    "        K: Rank of the factorization\n",
    "        niter: Number of iterations\n",
    "        W: Nonnegative matrix of size F x K used for initialization\n",
    "        H: Nonnegative matrix of size K x N used for initialization\n",
    "        verbose (bool): Prints errors during runtime\n",
    "    \n",
    "    Returns: \n",
    "        W: Nonnegative matrix of size F x K\n",
    "        H: Nonnegative matrix of size K x N\n",
    "        V_hat: Nonnegative matrix W*H of size F x N\n",
    "        cost: history of the IS divergence\n",
    "    \"\"\" \n",
    "    \n",
    "    eps = 1e-10 # used for numerical stability (to avoid division by zero for instance)\n",
    "    F, N = V.shape\n",
    "    \n",
    "    if W is None:\n",
    "        # initialize W\n",
    "        W = np.maximum(np.random.rand(F,K), eps)\n",
    "        \n",
    "    if H is None: \n",
    "        # initialize H\n",
    "        H = np.maximum(np.random.rand(K,N), eps)\n",
    "    \n",
    "    # compute V_hat\n",
    "    V_hat = W@H + eps\n",
    "    \n",
    "    # initialize array for computing the IS divergence\n",
    "    cost = np.zeros((niter,))\n",
    "    \n",
    "    # main loop\n",
    "    for n in np.arange(niter):\n",
    "        \n",
    "        # update W\n",
    "        # TO COMPLETE        \n",
    "        # W = \n",
    "                    \n",
    "        # compute V_hat\n",
    "        V_hat = W@H + eps\n",
    "        \n",
    "        # Update H\n",
    "        # TO COMPLETE\n",
    "        # H =\n",
    "        \n",
    "        # compute V_hat\n",
    "        V_hat = W@H + eps\n",
    "        \n",
    "        # compute IS divergence\n",
    "        cost[n] = IS_div(V, V_hat)\n",
    "        \n",
    "        # print IS divergence\n",
    "        if verbose:\n",
    "            print('IS-NMF: iteration %d / %d, cost=%f\\n' % (n, niter, cost[n]))\n",
    "    \n",
    "    return W, H, V_hat, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application on a toy example\n",
    "\n",
    "Let's first import some functions to plot the results of NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import power_to_db, amp_to_db, plot_NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate the functioning of the NMF procedure by means of a small toy example $V \\in \\mathbb{R}_{+}^{F \\times N}$ with $F=4$ and $N=8$. The rank parameter is set to $K=2$. You will see that different runs lead to very different decompositions. This is because initialization is very important for iterative algorithms used to solve non-convex optimization problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.array([ \n",
    "    [0, 1, 2, 3, 4, 5, 6, 7], \n",
    "    [0, 1, 2, 3, 3, 2, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    [7, 0, 0, 0, 0, 0, 0, 0], \n",
    "    [7, 6, 5, 4, 3, 2, 1, 0]    \n",
    "             ],dtype=float) + .1\n",
    "\n",
    "F, N = V.shape\n",
    "K = 2\n",
    "niter = 100\n",
    "\n",
    "W_init = np.abs(np.random.rand(F,K))\n",
    "H_init = np.abs(np.random.rand(K,N))\n",
    "\n",
    "print('Matrix V and randomly initialized matrices W and H')\n",
    "V_hat = W_init @ H_init\n",
    "error = IS_div(V, V_hat)\n",
    "plot_NMF(V, W_init, H_init, V_hat, error, figsize=(12,2), aspect='equal', wr=[1, 0.3, 1, 1])\n",
    "\n",
    "print('Matrix V and matrices W and H after training')\n",
    "W, H, V_hat, cost = IS_NMF(V, K, niter=niter, W=W_init, H=H_init, verbose=False)\n",
    "plot_NMF(V, W, H, V_hat, cost[-1], figsize=(12,2), aspect='equal', wr=[1, 0.3, 1, 1])\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(np.arange(niter), cost)\n",
    "plt.xlabel('Iteration index')\n",
    "plt.ylabel('IS divergence')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency on Rank Parameter\n",
    "\n",
    "In the NMF decomposition, the learned templates (columns of $W$) mainly capture characteristics of the dominating (in terms of coefficient values) first and last column of $V$, respectively. The example shows that the error between $V$ and the learned product $WH$ may still be large. \n",
    "\n",
    "Compute different NMF decompositions for $K \\in \\{1, 2, 3, 4\\}$ and conclude about the influence of this parameter on the quality of the approximation and on the interpretability of the the matrices $W$ and $H$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 100\n",
    "K_set = np.array([1, 2, 3, 4])\n",
    "for K in K_set: \n",
    "    print('K = %d'%K)\n",
    "    W_init =  np.abs(np.random.rand(F,K))\n",
    "    H_init = np.abs(np.random.rand(K,N)) \n",
    "    W, H, V_hat, cost = IS_NMF(V, K, niter=niter, W=W_init, H=H_init, verbose=False)\n",
    "    plot_NMF(V, W, H, V_hat, cost[-1], figsize=(12,2), aspect='equal', wr=[1, .5, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, using $K=1$ is the most restrictive case, where only a single template vector is used to \"explain\" the entire matrix $V$. Increasing $K$, one obtains better approximations of $V\\approx WH$. However, the matrices $W$ and $H$ are less structured and become harder to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity #2 - Unmixing a piano recording\n",
    "\n",
    "We have a recording of the following piece of music played by a piano. It contains four piano notes.\n",
    "\n",
    "<img src=\"./data/piano_recording.png\" width=\"600px\" align=\"middle\" alt=\"FMP_C8_F20b\">\n",
    "\n",
    "<audio src=\"./data/piano.wav\" type=\"audio/mpeg\" controls=\"controls\"></audio>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and plot the waveform\n",
    "\n",
    "wavefile = os.path.join('data', 'piano.wav')\n",
    "\n",
    "x, Fs = librosa.load(wavefile, sr=22050)\n",
    "\n",
    "time = np.arange(0,x.shape[0]/Fs, 1/Fs)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(time, x, 'k')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('amplitude')\n",
    "plt.title('waveform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the STFT and the spectrogram\n",
    "\n",
    "win_length = 1024\n",
    "hop_length = 512\n",
    "X = librosa.stft(x, n_fft=win_length, hop_length=hop_length, win_length=win_length, \n",
    "                 window='hann', center=True, pad_mode='constant')\n",
    "\n",
    "V = np.abs(X)**2\n",
    "\n",
    "freq = np.arange(0, V.shape[0])*Fs/win_length \n",
    "frames = np.arange(0, V.shape[1])*(hop_length/Fs)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(power_to_db(V), origin='lower', cmap='gray_r')\n",
    "plt.yticks(np.arange(0, V.shape[0], 100), np.round(freq[0:-1:100]).astype(int))\n",
    "plt.xticks(np.arange(0, V.shape[1], 100), np.round(frames[0:-1:100]).astype(int))\n",
    "plt.colorbar()   \n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('frequency (Hz)')\n",
    "plt.title('power spectrogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unmixing algorithm\n",
    "\n",
    "We want to unmix this recording, that is separate the audio signal into multiple individual components.\n",
    "\n",
    "We have to:\n",
    "\n",
    "1. Compute an NMF on the **power** spectrogram:\n",
    "\n",
    "$$\\mathbf{V} = |\\mathbf{X}|^{\\odot 2} \\approx \\mathbf{W}\\mathbf{H}$$\n",
    "\n",
    "2. Compute rank-1 power spectrogram matrices: \n",
    "\n",
    "$$\\hat{\\mathbf{V}}_k = ({\\mathbf{W}})_{:,k} ({\\mathbf{H}})_{k,:}$$\n",
    "\n",
    "3. Construct complex-valued STFT matrices using the phase of the mixture: \n",
    "\n",
    "$$\\hat{\\mathbf{X}}_k = \\hat{\\mathbf{V}}_k^{\\odot 1/2} \\exp(j \\arg(\\mathbf{X})) $$\n",
    "\n",
    "    (use ```np.angle()``` to compute the argument)\n",
    "\n",
    "4. Compute the inverse STFT to recover a waveform signal for each individual component.\n",
    "\n",
    "    (use ```librosa.istft(..., hop_length=hop_length, win_length=win_length, window='hann', center=True, length=x.shape[0]```, cf. [librosa documentation](http://man.hubwiz.com/docset/LibROSA.docset/Contents/Resources/Documents/generated/librosa.core.istft.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we compute the NMF on the mixture power spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute an NMF\n",
    "\n",
    "F, N = V.shape\n",
    "K = 8\n",
    "niter = 200\n",
    "\n",
    "W, H, V_hat, cost = IS_NMF(V, K, niter=niter, verbose=False)\n",
    "\n",
    "print('Matrix V and matrices W and H after training using K = %d'%K)\n",
    "plot_NMF(V, W, H, V_hat, cost[-1], figsize=(20,4), wr=[1, 1, 1, 1], power_spec=True)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(cost)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('IS divergence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now to complete the following cell to separate the individual audio components in the mixture. \n",
    "\n",
    "Hint: Try first to execute ```print(W[:,0].shape)``` and ```print(W[:,0,np.newaxis].shape)```. You will have to use this ```np.newaxis``` trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_hat = np.zeros((x.shape[0], K)) # will contain the waveforms of the components\n",
    "             \n",
    "for k in np.arange(K): \n",
    "    \n",
    "    #### TO COMPLETE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now listen to and look at the separated components in the following cell. This is great, right?\n",
    "\n",
    "You can play with the rank of the factorization, and listen to the reconstructed signals. \n",
    "\n",
    "Depending on the chosen rank, some components may capture the individual harmonic notes in the mixture, other components may capture percussive sounds, such as the attacks of the notes, or the release of the sustain pedal, which is clearly audible in the mixture, and some components may also simply correspond to low-amplitude noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_num = 0 # choose a component number\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.plot(time, x_hat[:,comp_num], 'k') # plot this component\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('amplitude')\n",
    "plt.title('waveform')\n",
    "plt.ylim([-1,1])\n",
    "\n",
    "ipd.Audio(x_hat[:,comp_num], rate=Fs) # listen to this component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if by summing the individual components (in the time domain) you recover the original mixture signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to recover the mixture by summing the individual components, we should replace step number 3 in the above algorithm by another process called Wiener filtering:\n",
    "\n",
    "$$\\hat{\\mathbf{X}}_k = \\frac{\\hat{\\mathbf{V}}_k}{\\sum_{k=1}^K \\hat{\\mathbf{V}}_k} \\odot \\mathbf{X}, $$\n",
    "\n",
    "where division is element wise. Remember that $\\sum_{k=1}^K \\hat{\\mathbf{V}}_k = \\mathbf{W}\\mathbf{H}$.\n",
    "\n",
    "Modify your implementation to use Wiener filtering.\n",
    "\n",
    "You can also test the method on different audio mixtures."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
